\documentclass[sigconf, natbib=false]{acmart}

\newcommand{\UV}{\mathcal{U}}
\newcommand{\PoI}{\mathcal{P}}

\begin{document}
   \title{Summary of Energy-Efficient 3D Vehicular Crowdsourcing For Disaster Response by Distributed Deep Reinforcement Learning}
   \author{John Dewey, jcd18c}
   \email{jcd18c@fsu.edu}
   \settopmatter{printacmref=false}
   \maketitle

   \section{INTRODUCTION}
   Natural disasters, such as earthquakes, hurricanes, and explosions, cause large amounts of damage, injuries, and casualties in short periods. Urgent situations require immediate action by rescue teams, as it is pivotal to do as much as possible in the first "golden 72 hours" when a disaster strikes since the survival rate falls to about 5-10\% after which. Unmanned vehicles (UVs) can improve efforts in disaster response as their deployment flexibility and information-collecting ability can reduce the amount of work required from people, explore disaster areas that are impossible for humans to explore, and focus the efforts of humans on rescue. However, people have sparsely researched dynamic UV trajectory planning in extreme conditions, and there are a few challenges to using UVs to explore disaster zones, such as making UVs explore the complete disaster area, making UVs cooperate, and planning trajectories of UVs in disaster areas with unevenly distributed point-of-interests (PoIs). The team behind the paper proposes DRL-DisasterVC(3D) to address this.

   \section{RELATED WORK}
   \subsection{Spatial Crowdsourcing (SC)}
   SC has been widely studied in theoretical and industrial applications like web mapping services, ride-hailing services, and online search and recommendation systems. One of the key issues in SC is task assignment (TA), where workers are allocated to spatial tasks to maximize/minimize a total weighted value. Two categories of TA are online and offline scenarios. For online scenarios, Liu et al. proposed a threshold-based greedy algorithm in "Budget-aware online task assignment in spatial crowdsourcing." For offline scenarios, Li et al. proposed a 3D stable spatial matching solution in "Three-Dimensional Stable Matching Problem for Spatial Crowdsourcing Platforms," and Ni et al. proposed a game-theoretic approach to find an optimal worker-task routing path that considers task dependencies in "Task Allocation in Dependency-aware Spatial Crowdsourcing."

   \subsection{Deep Reinforcement Learning (DRL)}
   Reinforcement learning (RL) is widely used for sequential decision-making problems through iteratively interacting with a time-slotted environment and formulated by a Markov Decision Process (MDP). A policy generates actions where a state transitions to its next state with a reward. DRL bridges RL and deep neural networks (DNNs) since DNNs allow learning intricate patterns and representations. Some representative DRL approaches include DQN, Rainbow, A3C, and DPPO; however, the state-of-the-art approach is IMPALA - the core of DeepMind AlphaStar. IMPALA simultaneously increases speed and decreases instability of DRL training, and it is considered the starting point of DRL-DisasterVC(3D).

   \section{PROBLEM FORMULATION}
   \subsection{System Model}
   The vehicular crowdsourcing (VC) task considers a set of UVs (drones and ground vehicles), $\UV$, and a set of PoIs, $\PoI$. The UVs work to explore the PoIs in a 3D work zone that contains a set of obstacles to avoid while exploring. The task duration is fixed and divided into $T$ equal timesteps of $\tau$ length, and each timestep contains two parts: UV movement and data collection. In the UV movement phase, a UV moves from its current position to a new position using an angle vector comprised of a polar and azimuthal angle and a moving distance (with fixed movement velocity). During data collection, UVs collect data from the nearest PoIs using a round-robin sensing policy. Under the assumption that PoIs have multiple antennas using orthogonal frequencies, transmissions from PoIs will not interfere with each other, so only the large-scale path loss effect between a PoI and UV is considered when measuring signal-to-noise ratio (SNR) and transmission rate. If the SNR is below a threshold, the data is considered too noisy and unusable. Therefore, the amount of data collected relies on data collection time, transmission rate, data dropout amount, and the number of PoIs serviced.

   \subsection{Problem Definition}
   Four metrics are used to define the UV navigation problem: data collection ratio, data dropout ratio, geographical fairness, and energy efficiency. The data collection ratio measures the average ratio of data collected from all UVs and the initial amount of data available data at all PoIs upon task completion, the data dropout rate measures data loss and the quality of the data collection due to the impact of low SNR, geographical fairness uses Jain's fairness index to measure diversity and uniformity in the disaster work zone, and energy efficiency measures energy consumption during the task and combines the previous three metrics to achieve the goals of each simultaneously. This allows the energy efficiency metric to measure the overall performance of the task; therefore, the optimization problem is maximizing energy efficiency.

   \section{SOLUTION}
   DRL-DisasterVC(3D) is a heuristic DRL method that consists of a distributed, asynchronous DRL framework. The framework is based on IMPALA and uses a repetitive experience relay for improved learning efficiency and an attentive 3D convolutional neural network (CNN) with auxiliary pixel control for spatial exploration.

   \subsection{Distributed DRL Framework with Repetetive Experience Relay (RER)}
   DRL-DisasterVC(3D) adapts the multi-actor-one-learner architecture from IMPALA where multiple actors (UVs) asynchronously work to generate MDP tuples by interacting with an environment. However, in IMPALA each MDP tuple is only used once, and the quality of learning from sampled experiences determines the accuracy and speed of training. Time and accuracy are essential in disaster recovery, so the team behind the paper introduces RER to enhance learning stability. The RER stores $b_M$ batches of experiences and can traverse these experiences $b_k$ times. After visiting a batch, the RER scrolls to a new batch. Every time a batch is visited, a counter is updated, and when the counter reaches $b_k$, the batch is thrown away and replaced with a new one. One thing to note is that the dimensions of the action space for multiple UVs expand tremendously compared to a single UV case, and this expansion leads to larger differences in local policies used by UVs. To stabilize this, a clipped target network is introduced. The target network of policies periodically synchronizes with the learner's policy network output, and policy update speed is limited using truncated importance sampling and a clipped ratio. When the clipped ratio is high, learning is fast but unstable, and as the clipped ratio is lowered, stability increases, but speed decreases. 
   
   \subsection{Attentive 3D CNN convolution with Auxiliary Pixel Control (PC)}
   DRL-DisasterVC(3D) uses two 3D CNN layers to calculate spatial feature representations of an input state. Since relationships exist between different spatial dimensions, a multi-head-relational attention (MHRA) module is placed after each CNN layer in the model to better extract them and make more reasonable trajectories for UVs. The MHRA module uses a number of independent heads with their own convolution filters to produce queries, keys, and values that indicate relational semantics. The outputs of the heads are concatenated and passed to the next layer in the model, and layer normalization and a shortcut to connect the input/output of the attention module are used to speed up model convergence. Furthermore, since PoI distribution is uneven and obstacle position is random, PC is introduced to increase geographical fairness. PC uses an intrinsic reward function that calculates the average absolute difference of adjacent input states and then uses a 3D deconvolutional network with a dueling structure to compute an additional value function from the fully connected layers in the model to update a loss function.
   
   \subsection{Algorithm Description}
   The algorithm has two parts: multiple actors and a central learner. The actors have a shared RER and asynchronously generate experiences for the central learner. The actors take in a local environment and policy network. Each actor has a buffer that stores multiple n-step trajectories collected from the local environment, and after the actor interacts with the environment n times, it sends the experience in a batch and starts the next timeslot. When the buffer is full, the actor sends it to the RER, and if the actor receives a broadcast hyperparameter from the central learner, the actor synchronizes its local policy with it. The central learner takes in a policy network, value network, PC network, and the target networks of the three previous networks. It starts by randomly initializing network weights and initializing each of the target networks, then it initializes the RER. During each gradient descent step, the learner samples a batch from the RER and computes a policy loss, value loss, entropy loss, and pixel loss used to make a total loss. The learner then uses gradient descent to optimize the total loss, updates the counter for the batch in the RER it visited, and discards and replaces a batch if its counter reaches the maximum number of visits allowed. After certain time thresholds are met, the central learner updates its target networks and broadcasts network weights to actors.

   
   \section{EVALUATION}
   \subsection{DisasterSim}
   To evaluate the proposed model, the team behind the paper designed a simulator (DisasterSim) for VC in disaster response scenarios. DisasterSim was built using Unity 2018.3.14f1, Python 3.7.7m, and Tensorboard 2.3.0. There are three layers to the simulation, the data layer, the model layer, and the visualization layer. The data layer contains scene configuration, such as scene assets, system parameters, and task settings, and model data (DNN structures, optimizers, and network parameters). The model layer contains four modules: the scene generator, hyperparameter tuning, model training, and testing modules. The scene generator loads scene configurations from the data layer and creates the 3D scene, the hyperparameter tuning module finds suitable hyperparameters by changing scene configuration and re-running model training, the model training module handles training the model, and the testing module handles model testing. The visualization layer provides a visual of the simulation in Unity.
   
   \subsection{Experiment}
   The team conducted an ablation study to measure the effectiveness of MHRA and PC and tested how hyperparameter tuning can affect performance. The study considered DRL-DisasterVC(3D) with all components, without PC, without MHRA, and without both. Different hyperparameter settings, specifically the number of heads used in MHRA and the number of traversals allowed for a batch in the RER, were tested to find optimal settings to improve performance. In the hyperparameter tuning test, other hyperparameters not mentioned follow the settings previously used in IMPALA. Finally, DRL-DisasterVC(3D) was tested against five baselines, IMPALA, IMPACT, CA2C, Shortest Path, and Random.
   
   \subsection{Results}
   Overall results were very promising. In the ablation study, it was found that the data collection ratio and geographical fairness of the model increased when using PC showing that PC improves spatial exploration. Furthermore, energy efficiency significantly decreases when MHRA is not used when compared to when PC is not used. This makes sense, as PC sacrifices energy efficiency to improve spatial exploration, and MHRA helps mitigate that shortcoming by extracting more spatial relational features. Also, when comparing DRL-DisasterVC(3D) with all components and without MHRA and PC, the version with all components performs 17.3\% better confirming the benefits of using MHRA and PC together. In the hyperparameter tuning testing, it was found that using too many or too few heads with MHRA negatively affects performance. Using too few heads doesn't allow the model to extract more multi-level relational representations that help the model make better decisions, but using too many heads results in difficulties of model convergence due to a significant increase in the number of network parameters. The same holds for the number of traversals for a batch in the RER, as too few traversals won't allow RER to improve sample efficiency and learning quality from limited experience, but using too many traversals overfits due to a shortage of experience diversity. Finally, when comparing against the baselines, DRL-DisasterVC(3D) outperforms each in terms of the four metrics presented in the paper (data collection ratio, data dropout ratio, geographical fairness, and energy efficiency). Testing the impact of the number of PoIs shows that increased numbers can lead to increased data density in local areas, which traps UVs into a local optimal without effective spatial exploration and relational representations created by the PC and MHRA. Furthermore, testing the impact of the number of UVs shows that as the number of UVs increases, so does the data collection ratio and geographical fairness because more UVs naturally cover more area. However, energy efficiency decreases due to multiplied energy consumption, but the MHRA and PC methods enforce UV cooperation, which helps mitigate the drop in energy efficiency. Also, testing the impact of the SNR threshold shows that a high SNR threshold decreases the data collection ratio and increases the data dropout ratio monotonically, yet DRL-DisasterVC(3D) consistently outperformed all other baselines regardless of the SNR threshold. Finally, a complexity analysis shows that DRL-DisasterVC(3D) converges faster than the other DRL methods tested due to improved sample efficiency brought by the RER and learning stability brought by MHRA and PC, and the improved network structure causes no extra overhead as the running time of DRL-DisasterVC(3D) is almost identical to IMPACT and only slightly higher than IMPALA and CA2C.
   
   \section{STRENGTHS}
   The solution provided in the paper effectively solves or mitigates issues presented by the challenges introduced. Using MHRA and PC ensures that UVs cooperate, fully explore a disaster area, and properly explore disaster areas with uneven distributions of PoIs. Furthermore, the additions to IMPALA done in the paper add little to no overhead, so the use of DRL-DisasterVC(3D) holds no time disadvantage compared to the current state-of-the-art method. Besides this, DRL-DisasterVC(3D) outperforms all other baselines (including the state-of-the-art method), so the model is seemingly a total improvement over current methods with no negatives.
   
   \section{WEAKNESSES}
   One aspect of the paper I found to be a weakness is the number of figures and layout of certain figures. While there are excellent figures in the paper showing how the model works at a high level or how the testing simulator works, some things rely on equations and conceptual understanding to convey how a module/method works. For example, the paper gives a detailed explanation of the clipped target network and equations that show its target function, loss functions, etc.; however, reading it was initially not clear to me, and I needed to review it several times before I felt I understood it, which can be mitigated by adding an appropriate figure to show how it functions. Besides that, a figure in the paper that shows how DRL-DisasterVC(3D) works on a high level accurately conveys the information it wants to; however, the layout of the figure is confusing and takes more analysis than necessary to be understandable. Furthermore, there are some assumptions taken in the paper that will not be applicable in a real-world scenario. For instance, it is assumed that UV movement velocity is fixed and PoIs are equipped with multiple antennas operating at orthogonal frequencies. Though these assumptions make sense for the proof of concept, if the work is to be brought to a real-world setting, these assumptions must be stricken and handled.
   
   \section{YOUR SOLUTION}
   To improve the paper, I would begin by splitting Figure 1 into multiple figures that show how the various aspects of DRL-DisasterVC(3D) work more clearly instead of trying to fit all of the mechanisms into one figure. Next, I would analyze all the assumptions made in the paper, determine which are viable to explore for future research and improvement and add a section to the paper outlining future/potential work. Finally, I would try to make a real-world scenario for testing to add to the simulation used for testing. For example, something like deploying a set of drones to explore marked PoIs in a warehouse that has obstacles strewn about.
\end{document}