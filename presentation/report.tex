\documentclass[sigconf, natbib=false]{acmart}

\newcommand{\UV}{\mathcal{U}}
\newcommand{\PoI}{\mathcal{P}}

\begin{document}
   \title{Summary of Energy-Efficient 3D Vehicular Crowdsourcing For Disaster Response by Distributed Deep Reinforcement Learning}
   \author{John Dewey, jcd18c}
   \email{jcd18c@fsu.edu}
   \settopmatter{printacmref=false}
   \maketitle

   \section{INTRODUCTION}
   Natural disasters, such as earthquakes, hurricanes, and explosions, cause large amounts of damage, injuries, and casualties in short periods of time. Urgent situations require immediate action by rescue teams, as it is pivotal to do as much as possible in the "golden 72-hours" since after which survival rate falls to about 5-10\%. Use of unmanned vehicles (UVs) can improve efforts in disaster response as their deployment flexibility and information collecting ability can reduce amount of work required from people, explore disaster areas that are impossible for humans to explore, and focus the efforts of humans on rescue. However, the amount of research in dynamic UB trajectory planning in extreme conditions is sparsely researched, and there are a few challenges that must be addressed to using UVs to explore disaster zones such as making UVs explore the complete disaster area, making UVs cooperate, and planning trajectories of UVs in disaster areas with unevenly distributed point-of-interests (PoIs). To address this, DRL-DISASTERVC(3D) is proposed.

   \section{RELATED WORK}
   \subsection{Spatial Crowdsourcing (SC)}
   SC has been widely studied in both theoretical and various inductrial applications like web mapping services, ride-hailing services, and online search and recommendation systems. One of the key issues in SC is task assignment (TA) where workers are allocated to spatial tasks to maximize/minimize a total weighted value. Two categories of TA are online and offline scenarios. For online scenarios, Liu et al. proposed a threshold-based greedy algorithm in "Budget-aware online task assignment in spatial crowdsourcing." For offline scenarios, Li et al. proposed a 3D stable spatial matching solution in "," and Ni et al. proposed a game-theoretic approach to find an optimal worker-task routing path that considers task dependencies in "".

   \subsection{Deep Reinforcement Learning (DRL)}
   Reinforcement learning (RL) is widely used for sequential decision-making problems through iteratively interacting with a time-slotted environment, and are usually formulated by a Markov Decision Process (MDP). Actions are generated by a policy where a state transitions to its next state with a reward. DRL bridges RL and deep neural networks (DNNs) since DNNs allow the ability to learn intricate patterns and representations. Some representative DRL approaches include DQN, Rainbow, A3C, and DPPO; however, the state of the art approach is IMPALA - the core of DeepMind AlphaStar. IMPALA simultaneously increases speed and decreases instability of DRL training, and it is considered the starting point of DRL-DISASTERVC(3D).

   \section{PROBLEM FORMULATION}
   \subsection{System Model}
   The vehicular crowdsourcing (VC) task considers a set of UVs (drones and unmanned ground vehicles), $\UV$, and a set of PoIs, $\PoI$. The UVs work to explore the PoIs in a 3D workzone that contains a set of obstacles to avoid while exploring. The task duration is fixed and divided into $T$ equal timesteps of $\tau$ length, and each timestep is contains two parts, UV movement and data collection. The UV movement phase, a UV moves from its current position to a new position using an agle vector comprised of a polar and azimuthal angle and a moving distance (movement velocity is fixed). In the data collection part, a round robin sensing policy is used to collect data from a number of the nearest PoIs to a UV. Under the assumption that PoIs have multiple antennas using orthogonal frequencies, transmissions from PoIs will not interfere with eachother, so only the large scale pathloss effect between a PoI and UV is considered when measuring signal to noise ratio (SNR) and transmission rate. If the SNR is below a threshold, the data is considered too noisy and unusable. Therefore, the amount of data collected relies on data collection time, transmission rate, data dropout amount, and the number of PoIs serviced.

   \subsection{Problem Definition}
   Four metrics are used to define the UV navigation problem: data collection ratio, data dropout ratio, geographical fairness, and energy efficiency. The data collection ratio measures the average ratio of data collected from all UVs and the initial amount of data available data at all PoIs apon task completion, the data dropout rate measures data loss and the quality of the data collection due to impact of low SNR, geographical fairness uses Jain's fairness index to measure diversity and uniformity in the disaster workzone, and energy efficiency measures energy consumption during the task and combines the previous three metrics to achieve the goals of each simultaneously. This allows the energy efficiency metric to measure the overall performance of the task; therefore, the optimization problem can be viewed as maximizing energy efficiency. However, maximizing 

   \section{SOLUTION}
   DRL-DISASTERVC(3D) is a heuristic DRL method that consists of a distributed, asynchronous DRL framework. The framefork is based on IMPALA and uses a repetetive experience relay for improved learning efficiency an attentive 3D convolutional neural network (CNN) with auxiliary pixel control for spatial exploration.
   \subsection{Distributed DRL Framework with RER}
   \subsection{Attentive 3D CNN convolution with Pixel Control}
   \subsection{Algorithm Design}

   \section{EVALUATION}
   \subsection{DISASTERSIM}
   \subsection{Experiment}
   \subsection{Results}

   \section{STRENGTHS}

   \section{WEAKNESSES}

   \section{YOUR SOLUTION}

\end{document}